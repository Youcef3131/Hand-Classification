{"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.1"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"f6b2ae9b","cell_type":"markdown","source":" Imports and Seeding","metadata":{}},{"id":"e49fe462","cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import models, transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom PIL import Image\n\n# For reproducibility\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything()","metadata":{},"outputs":[],"execution_count":1},{"id":"83e7b7c3","cell_type":"markdown","source":"Device and Hyperparameters","metadata":{}},{"id":"31228f07","cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Hyperparameters\nBATCH_SIZE = 20\nNUM_EPOCHS = 30  # Reduced epochs since we're training a combined model\nLEARNING_RATE = 0.0001\nIMAGE_SIZE = 128\nNUM_CLASSES = 14  # HG14 has 14 classes\nDROPOUT_RATE = 0.5","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n"]}],"execution_count":2},{"id":"03c638d8","cell_type":"markdown","source":"Paths and Transforms","metadata":{}},{"id":"dd597dfe","cell_type":"code","source":"# Data paths - Replace with your actual paths\nDATA_PATH = \"./HG14_split\"\nTRAIN_PATH = os.path.join(DATA_PATH, \"train\")\nVAL_PATH = os.path.join(DATA_PATH, \"validation\")\nTEST_PATH = os.path.join(DATA_PATH, \"test\")\n\n# Data transformations\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_test_transform = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{},"outputs":[],"execution_count":3},{"id":"1b9c469e","cell_type":"markdown","source":"Datasets and Loaders","metadata":{}},{"id":"92632a36","cell_type":"markdown","source":"Model Definition","metadata":{}},{"id":"dab2bd86","cell_type":"code","source":"class DirichletEnsembleModel(nn.Module):\n    \"\"\"\n    A combined model using all four pre-trained networks with learnable weights\n    \"\"\"\n    def __init__(self, num_classes=NUM_CLASSES):\n        super(DirichletEnsembleModel, self).__init__()\n        \n        # Initialize the four base models\n        self.vgg16 = self._get_vgg16(num_classes)\n        self.vgg19 = self._get_vgg19(num_classes)\n        self.mobilenet = self._get_mobilenet(num_classes)\n        self.mobilenet_v2 = self._get_mobilenet_v2(num_classes)\n        \n        # Initialize ensemble weights as learnable parameters\n        # Start with equal weights (will be normalized in forward pass)\n        self.ensemble_weights = nn.Parameter(torch.ones(4) / 4)\n        \n    def _get_vgg16(self, num_classes):\n        model = models.vgg16(pretrained=True)\n        # Modify classifier\n        model.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=DROPOUT_RATE),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=DROPOUT_RATE),\n            nn.Linear(4096, 512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, num_classes)\n        )\n        return model\n    \n    def _get_vgg19(self, num_classes):\n        model = models.vgg19(pretrained=True)\n        # Modify classifier\n        model.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=DROPOUT_RATE),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=DROPOUT_RATE),\n            nn.Linear(4096, 512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, num_classes)\n        )\n        return model\n    \n    def _get_mobilenet(self, num_classes):\n        model = models.mobilenet_v2(pretrained=True)\n        # Modify classifier\n        model.classifier = nn.Sequential(\n            nn.Dropout(p=DROPOUT_RATE),\n            nn.Linear(1280, 512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, num_classes)\n        )\n        return model\n    \n    def _get_mobilenet_v2(self, num_classes):\n        model = models.mobilenet_v2(pretrained=True)\n        # Modify classifier\n        model.classifier = nn.Sequential(\n            nn.Dropout(p=DROPOUT_RATE),\n            nn.Linear(1280, 512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, num_classes)\n        )\n        return model\n    \n    def forward(self, x):\n        # Get logits from each model\n        vgg16_out = self.vgg16(x)\n        vgg19_out = self.vgg19(x)\n        mobilenet_out = self.mobilenet(x)\n        mobilenet_v2_out = self.mobilenet_v2(x)\n        \n        # Convert logits to probabilities\n        vgg16_probs = torch.softmax(vgg16_out, dim=1)\n        vgg19_probs = torch.softmax(vgg19_out, dim=1)\n        mobilenet_probs = torch.softmax(mobilenet_out, dim=1)\n        mobilenet_v2_probs = torch.softmax(mobilenet_v2_out, dim=1)\n        \n        # Normalize ensemble weights using softmax to ensure they sum to 1\n        weights = torch.softmax(self.ensemble_weights, dim=0)\n        \n        # Weighted ensemble (Dirichlet ensemble)\n        ensemble_out = (\n            weights[0] * vgg16_probs + \n            weights[1] * vgg19_probs + \n            weights[2] * mobilenet_probs + \n            weights[3] * mobilenet_v2_probs\n        )\n        \n        # Convert back to logits for loss calculation (optional)\n        # You could also directly return ensemble_out if using a different loss function\n        ensemble_logits = torch.log(ensemble_out + 1e-8)  # Add small epsilon to avoid log(0)\n        \n        return ensemble_logits","metadata":{},"outputs":[],"execution_count":5},{"id":"7017bd33","cell_type":"markdown","source":"Training Function","metadata":{}},{"id":"02d80635","cell_type":"code","source":"# Training function\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs):\n    \"\"\"\n    Train the ensemble model\n    \"\"\"\n    best_val_acc = 0.0\n    best_model_weights = None\n    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n    \n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        \n        # Training phase\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        \n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = correct / total\n        history['train_loss'].append(epoch_loss)\n        history['train_acc'].append(epoch_acc)\n        \n        # Validation phase\n        model.eval()\n        val_running_loss = 0.0\n        val_correct = 0\n        val_total = 0\n        \n        with torch.no_grad():\n            for inputs, labels in tqdm(val_loader, desc=\"Validation\"):\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                \n                val_running_loss += loss.item() * inputs.size(0)\n                _, predicted = torch.max(outputs, 1)\n                val_total += labels.size(0)\n                val_correct += (predicted == labels).sum().item()\n        \n        val_epoch_loss = val_running_loss / len(val_loader.dataset)\n        val_epoch_acc = val_correct / val_total\n        history['val_loss'].append(val_epoch_loss)\n        history['val_acc'].append(val_epoch_acc)\n        \n        # Print current ensemble weights\n        weights = torch.softmax(model.ensemble_weights, dim=0).detach().cpu().numpy()\n        print(f\"Ensemble weights: VGG16: {weights[0]:.4f}, VGG19: {weights[1]:.4f}, MobileNet: {weights[2]:.4f}, MobileNetV2: {weights[3]:.4f}\")\n        \n        # Adjust learning rate\n        scheduler.step(val_epoch_loss)\n        \n        print(f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}\")\n        print(f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n        \n        # Save best model\n        if val_epoch_acc > best_val_acc:\n            best_val_acc = val_epoch_acc\n            best_model_weights = model.state_dict().copy()\n            torch.save(model.state_dict(), \"ensemble_best.pth\")\n    \n    print(f'Best val accuracy: {best_val_acc:.4f}')\n    \n    # Load best model weights\n    model.load_state_dict(best_model_weights)\n    \n    return model, history\n","metadata":{},"outputs":[],"execution_count":6},{"id":"0f40c25b","cell_type":"markdown","source":"Evaluation and Utility Functions","metadata":{}},{"id":"64adcfd7","cell_type":"code","source":"# Evaluation function\ndef evaluate_model(model, test_loader, criterion):\n    \"\"\"\n    Evaluate model performance on test data\n    \"\"\"\n    model.eval()\n    test_loss = 0.0\n    test_correct = 0\n    test_total = 0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            test_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            test_total += labels.size(0)\n            test_correct += (predicted == labels).sum().item()\n            \n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    test_loss = test_loss / len(test_loader.dataset)\n    test_acc = test_correct / test_total\n    \n    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n    \n    return test_loss, test_acc, all_preds, all_labels\n\n# Plot confusion matrix\ndef plot_confusion_matrix(y_true, y_pred, classes, title=\"Confusion Matrix\"):\n    \"\"\"\n    Create and plot a confusion matrix visualization\n    \"\"\"\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(title)\n    plt.savefig(f\"{title.lower().replace(' ', '_')}.png\")\n    plt.show()\n\n# Plot training and validation curves\ndef plot_learning_curves(history):\n    \"\"\"\n    Plot training and validation loss and accuracy curves\n    \"\"\"\n    plt.figure(figsize=(12, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(history['train_loss'], label='Train Loss')\n    plt.plot(history['val_loss'], label='Validation Loss')\n    plt.title('Loss Curves')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(history['train_acc'], label='Train Accuracy')\n    plt.plot(history['val_acc'], label='Validation Accuracy')\n    plt.title('Accuracy Curves')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig(\"ensemble_learning_curves.png\")\n    plt.show()\n\n# Function to use the trained ensemble for prediction\ndef predict_gesture(model, image_path):\n    \"\"\"\n    Use the trained ensemble model to predict hand gesture from an image\n    \n    Args:\n        model: Trained ensemble model\n        image_path: Path to the image file\n        \n    Returns:\n        Predicted class index and class name\n    \"\"\"\n    # Load image\n    transform = val_test_transform\n    \n    image = Image.open(image_path).convert('RGB')\n    image_tensor = transform(image).unsqueeze(0).to(device)\n    \n    # Make prediction\n    model.eval()\n    with torch.no_grad():\n        output = model(image_tensor)\n        pred_class = torch.argmax(output, dim=1).item()\n    \n    # Get class name\n    class_names = train_dataset.classes\n    pred_class_name = class_names[pred_class]\n    \n    return pred_class, pred_class_name\n","metadata":{},"outputs":[],"execution_count":7},{"id":"f1f7d154","cell_type":"markdown","source":"Main","metadata":{}},{"id":"c07ec5f8","cell_type":"code","source":"def main():\n    \"\"\"\n    Main execution function that implements the combined Dirichlet ensemble approach\n    \"\"\"\n    # Create the ensemble model\n    model = DirichletEnsembleModel(NUM_CLASSES)\n    model = model.to(device)\n    \n    # Check if pre-trained model exists\n    model_path = \"ensemble_best.pth\"\n    if os.path.exists(model_path):\n        print(\"Loading pre-trained ensemble model...\")\n        model.load_state_dict(torch.load(model_path))\n    else:\n        print(\"Training ensemble model from scratch...\")\n        # Set up training\n        criterion = nn.CrossEntropyLoss()\n        \n        # Create parameter groups with different learning rates\n        # Lower learning rate for pre-trained layers\n        base_model_params = []\n        for name, param in model.named_parameters():\n            if not name.startswith('ensemble_weights'):\n                base_model_params.append(param)\n        \n        optimizer = optim.Adam([\n            {'params': base_model_params, 'lr': LEARNING_RATE * 0.1},  # Lower learning rate for base models\n            {'params': model.ensemble_weights, 'lr': LEARNING_RATE}    # Higher learning rate for ensemble weights\n        ])\n        \n        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n        \n        # Train model\n        model, history = train_model(model, train_loader, val_loader, criterion, optimizer, \n                                     scheduler, NUM_EPOCHS)\n        \n        # Plot learning curves\n        plot_learning_curves(history)\n    \n    # Display final ensemble weights\n    weights = torch.softmax(model.ensemble_weights, dim=0).detach().cpu().numpy()\n    print(\"\\nFinal Ensemble Weights:\")\n    print(f\"VGG16: {weights[0]:.4f}\")\n    print(f\"VGG19: {weights[1]:.4f}\")\n    print(f\"MobileNet: {weights[2]:.4f}\")\n    print(f\"MobileNetV2: {weights[3]:.4f}\")\n    \n    # Evaluate on test set\n    criterion = nn.CrossEntropyLoss()\n    test_loss, test_acc, preds, labels = evaluate_model(model, test_loader, criterion)\n    \n    # Plot confusion matrix\n    plot_confusion_matrix(labels, preds, train_dataset.classes, \"Ensemble Confusion Matrix\")\n    \n    # Print classification report\n    print(\"\\nEnsemble Classification Report:\")\n    print(classification_report(labels, preds, target_names=train_dataset.classes))\n    \n    return model\n\nif __name__ == \"__main__\":\n    main()","metadata":{},"outputs":[],"execution_count":null}]}